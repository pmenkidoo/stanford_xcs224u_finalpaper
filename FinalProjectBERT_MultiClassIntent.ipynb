{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from scipy.special import softmax\n"
      ],
      "metadata": {
        "id": "MdoL92AbH0dl"
      },
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset of intents\n",
        "df=pd.read_csv('dataset_full_noOR.csv')"
      ],
      "metadata": {
        "id": "W0fWj85tISM8"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = list(df.text.astype(str))\n",
        "labels = list(df.label.astype(str))"
      ],
      "metadata": {
        "id": "Hzkmb4rZIXZz"
      },
      "execution_count": 325,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize input sentences\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "encoded_inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Convert text labels to numerical labels\n",
        "label_map = {label: i for i, label in enumerate(set(labels))}\n",
        "numerical_labels = [label_map[label] for label in labels]\n",
        "\n",
        "# Split data into train and validation sets\n",
        "train_inputs, val_inputs, train_labels, val_labels = train_test_split(encoded_inputs['input_ids'],\n",
        "                                                                      numerical_labels,\n",
        "                                                                      test_size=0.2,\n",
        "                                                                      random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "train_inputs_tensor = torch.tensor(train_inputs)\n",
        "val_inputs_tensor = torch.tensor(val_inputs)\n",
        "train_labels_tensor = torch.tensor(train_labels)\n",
        "val_labels_tensor = torch.tensor(val_labels)\n",
        "\n",
        "# Create attention masks\n",
        "train_attention_masks = torch.tensor([[int(token_id != tokenizer.pad_token_id) for token_id in input_ids] for input_ids in train_inputs])\n",
        "val_attention_masks = torch.tensor([[int(token_id != tokenizer.pad_token_id) for token_id in input_ids] for input_ids in val_inputs])\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(train_inputs_tensor, train_attention_masks, train_labels_tensor)\n",
        "val_dataset = TensorDataset(val_inputs_tensor, val_attention_masks, val_labels_tensor)\n",
        "\n",
        "# Define batch size and create DataLoaders\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)\n",
        "\n",
        "# Load pre-trained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_map))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnbCoEuveQaN",
        "outputId": "1de3d980-3d9a-476b-9845-9f7b92f8e81a"
      },
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-326-7eafa03295be>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_inputs_tensor = torch.tensor(train_inputs)\n",
            "<ipython-input-326-7eafa03295be>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_inputs_tensor = torch.tensor(val_inputs)\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Training loop with progress bar\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    val_predictions = []\n",
        "    val_true_labels = []\n",
        "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\"):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Evaluate on validation set during training\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_ids, attention_mask=attention_mask).logits\n",
        "            predictions = np.argmax(logits.detach().numpy(), axis=1)\n",
        "            val_predictions.extend(predictions)\n",
        "            val_true_labels.extend(labels.numpy())\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(val_true_labels, val_predictions)\n",
        "    precision = precision_score(val_true_labels, val_predictions, average='macro')\n",
        "    recall = recall_score(val_true_labels, val_predictions, average='macro')\n",
        "    f1 = f1_score(val_true_labels, val_predictions, average='macro')\n",
        "\n",
        "    print(f\"Epoch {epoch+1}:\")\n",
        "    print(f\"  Training loss: {train_loss / len(train_dataloader):.4f}\")\n",
        "    print(f\"  Validation Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  Validation Precision: {precision:.4f}\")\n",
        "    print(f\"  Validation Recall: {recall:.4f}\")\n",
        "    print(f\"  Validation F1-score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "val_predictions = []\n",
        "val_true_labels = []\n",
        "for batch in val_dataloader:\n",
        "    input_ids, attention_mask, labels = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    predictions = np.argmax(logits.detach().numpy(), axis=1)\n",
        "    val_predictions.extend(predictions)\n",
        "    val_true_labels.extend(labels.numpy())\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(val_true_labels, val_predictions)\n",
        "precision = precision_score(val_true_labels, val_predictions, average='macro')\n",
        "recall = recall_score(val_true_labels, val_predictions, average='macro')\n",
        "f1 = f1_score(val_true_labels, val_predictions, average='macro')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6yPH9ZtION0",
        "outputId": "65fea5d3-ba00-4b0e-ab9e-0212c51a65d7"
      },
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 80/80 [00:39<00:00,  2.04it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "  Training loss: 3.2602\n",
            "  Validation Accuracy: 0.4591\n",
            "  Validation Precision: 0.8035\n",
            "  Validation Recall: 0.4353\n",
            "  Validation F1-score: 0.5127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 80/80 [00:38<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "  Training loss: 1.1889\n",
            "  Validation Accuracy: 0.9827\n",
            "  Validation Precision: 0.9790\n",
            "  Validation Recall: 0.9793\n",
            "  Validation F1-score: 0.9769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 80/80 [00:38<00:00,  2.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3:\n",
            "  Training loss: 0.4095\n",
            "  Validation Accuracy: 0.9866\n",
            "  Validation Precision: 0.9845\n",
            "  Validation Recall: 0.9845\n",
            "  Validation F1-score: 0.9844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 80/80 [00:38<00:00,  2.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4:\n",
            "  Training loss: 0.2024\n",
            "  Validation Accuracy: 0.9858\n",
            "  Validation Precision: 0.9834\n",
            "  Validation Recall: 0.9833\n",
            "  Validation F1-score: 0.9829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 80/80 [00:38<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5:\n",
            "  Training loss: 0.1284\n",
            "  Validation Accuracy: 0.9882\n",
            "  Validation Precision: 0.9862\n",
            "  Validation Recall: 0.9862\n",
            "  Validation F1-score: 0.9862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 80/80 [00:38<00:00,  2.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6:\n",
            "  Training loss: 0.0951\n",
            "  Validation Accuracy: 0.9921\n",
            "  Validation Precision: 0.9908\n",
            "  Validation Recall: 0.9908\n",
            "  Validation F1-score: 0.9908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 80/80 [00:38<00:00,  2.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7:\n",
            "  Training loss: 0.0757\n",
            "  Validation Accuracy: 0.9929\n",
            "  Validation Precision: 0.9918\n",
            "  Validation Recall: 0.9918\n",
            "  Validation F1-score: 0.9918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 80/80 [00:38<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8:\n",
            "  Training loss: 0.0587\n",
            "  Validation Accuracy: 0.9984\n",
            "  Validation Precision: 0.9984\n",
            "  Validation Recall: 0.9981\n",
            "  Validation F1-score: 0.9982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 80/80 [00:38<00:00,  2.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9:\n",
            "  Training loss: 0.0506\n",
            "  Validation Accuracy: 0.9961\n",
            "  Validation Precision: 0.9957\n",
            "  Validation Recall: 0.9955\n",
            "  Validation F1-score: 0.9954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 80/80 [00:38<00:00,  2.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10:\n",
            "  Training loss: 0.0432\n",
            "  Validation Accuracy: 0.9969\n",
            "  Validation Precision: 0.9965\n",
            "  Validation Recall: 0.9964\n",
            "  Validation F1-score: 0.9963\n",
            "Accuracy: 0.9749216300940439\n",
            "Precision: 0.9677276746242263\n",
            "Recall: 0.981896551724138\n",
            "F1-score: 0.9725161710642655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample input text\n",
        "input_text = \"Please compile the sales results for each day and location over the last seven weeks.\"\n",
        "\n",
        "# Tokenize input text\n",
        "input_encoding = tokenizer(input_text, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Perform prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    input_ids = input_encoding['input_ids']\n",
        "    attention_mask = input_encoding['attention_mask']\n",
        "    logits = model(input_ids, attention_mask=attention_mask).logits\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    top_k_probabilities, top_k_indices = torch.topk(probabilities, k=3, dim=1)\n",
        "\n",
        "# Convert top k predicted labels back to text labels\n",
        "top_k_predictions = [[label_map_inverse[idx.item()] for idx in top_k_indices_row] for top_k_indices_row in top_k_indices]\n",
        "\n",
        "# Convert tensor to list for easier manipulation\n",
        "top_k_probabilities = top_k_probabilities.numpy().tolist()\n",
        "\n",
        "# Display top 3 predictions and their confidence levels\n",
        "for i, (preds, probs) in enumerate(zip(top_k_predictions, top_k_probabilities), 1):\n",
        "    print(f\"Top {i} Predictions:\")\n",
        "    for pred, prob in zip(preds, probs):\n",
        "        print(f\"  Label: {pred}, Confidence Level (%): {prob * 100:.2f}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw5BzW01Hpy9",
        "outputId": "21a93a31-472b-4826-fb95-ebcd9800d7ba"
      },
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 Predictions:\n",
            "  Label: Request for Daily Sales Breakdown by Location - Time Horizon Specific, Confidence Level (%): 97.23\n",
            "  Label: Request for Sales Forecast by Location, Confidence Level (%): 0.12\n",
            "  Label: Sales Summary - Top 10 Employees - Total Sales by Store - Current Week, Confidence Level (%): 0.10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample input text\n",
        "input_text = \"Please compile the sales forecast for the next 3 weeks for product hello_kitty.\"\n",
        "\n",
        "# Tokenize input text\n",
        "input_encoding = tokenizer(input_text, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Perform prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    input_ids = input_encoding['input_ids']\n",
        "    attention_mask = input_encoding['attention_mask']\n",
        "    logits = model(input_ids, attention_mask=attention_mask).logits\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    top_k_probabilities, top_k_indices = torch.topk(probabilities, k=3, dim=1)\n",
        "\n",
        "# Convert top k predicted labels back to text labels\n",
        "top_k_predictions = [[label_map_inverse[idx.item()] for idx in top_k_indices_row] for top_k_indices_row in top_k_indices]\n",
        "\n",
        "# Convert tensor to list for easier manipulation\n",
        "top_k_probabilities = top_k_probabilities.numpy().tolist()\n",
        "\n",
        "# Display top 3 predictions and their confidence levels\n",
        "for i, (preds, probs) in enumerate(zip(top_k_predictions, top_k_probabilities), 1):\n",
        "    print(f\"Top {i} Predictions:\")\n",
        "    for pred, prob in zip(preds, probs):\n",
        "        print(f\"  Label: {pred}, Confidence Level (%): {prob * 100:.2f}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CRw7SCpNAC_",
        "outputId": "4a3abe37-feaf-4da3-9e5a-3d1dde699951"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 Predictions:\n",
            "  Label: Request for Daily Sales Breakdown by Location - Time Horizon Specific, Confidence Level (%): 15.49\n",
            "  Label: Request for Sales Forecast by Location, Confidence Level (%): 7.42\n",
            "  Label: Request for Sales Breakdown by Product Category, Confidence Level (%): 5.74\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample input text\n",
        "input_text = \"Once upon a time there was light in my life But now there's only love in the dark Nothing I can say A total eclipse of the heart\"\n",
        "\n",
        "# Tokenize input text\n",
        "input_encoding = tokenizer(input_text, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Perform prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    input_ids = input_encoding['input_ids']\n",
        "    attention_mask = input_encoding['attention_mask']\n",
        "    logits = model(input_ids, attention_mask=attention_mask).logits\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    top_k_probabilities, top_k_indices = torch.topk(probabilities, k=3, dim=1)\n",
        "\n",
        "# Convert top k predicted labels back to text labels\n",
        "top_k_predictions = [[label_map_inverse[idx.item()] for idx in top_k_indices_row] for top_k_indices_row in top_k_indices]\n",
        "\n",
        "# Convert tensor to list for easier manipulation\n",
        "top_k_probabilities = top_k_probabilities.numpy().tolist()\n",
        "\n",
        "# Display top 3 predictions and their confidence levels\n",
        "for i, (preds, probs) in enumerate(zip(top_k_predictions, top_k_probabilities), 1):\n",
        "    print(f\"Top {i} Predictions:\")\n",
        "    for pred, prob in zip(preds, probs):\n",
        "        print(f\"  Label: {pred}, Confidence Level (%): {prob * 100:.2f}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6facijuNHcx",
        "outputId": "5efaf087-e0e3-4f6a-f849-38adbde4d531"
      },
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 Predictions:\n",
            "  Label: Unrelated_Random_Sentence, Confidence Level (%): 75.43\n",
            "  Label: Sales Report - Product Specific - Yesterday, Confidence Level (%): 4.24\n",
            "  Label: Sales Report - Product Category Specific - Yesterday, Confidence Level (%): 3.21\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample input text\n",
        "input_text = \"A company makes raincoats and umbrellas with images of Latin alphabet on them using a printing machine. Due to the popularity of Latin alphabet, the company must make at least 1200 raincoats or umbrellas, in any combination, per week. Also, in one week, the printing machine must be kept running for at least 70 hours. A raincoat takes 0.3 hours of printing time and costs $7. An umbrella takes 0.5 hours of printing time and costs $12. Formulate this problem so as to minimize total production costs.\"\n",
        "# Tokenize input text\n",
        "input_encoding = tokenizer(input_text, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Perform prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    input_ids = input_encoding['input_ids']\n",
        "    attention_mask = input_encoding['attention_mask']\n",
        "    logits = model(input_ids, attention_mask=attention_mask).logits\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    top_k_probabilities, top_k_indices = torch.topk(probabilities, k=3, dim=1)\n",
        "\n",
        "# Convert top k predicted labels back to text labels\n",
        "top_k_predictions = [[label_map_inverse[idx.item()] for idx in top_k_indices_row] for top_k_indices_row in top_k_indices]\n",
        "\n",
        "# Convert tensor to list for easier manipulation\n",
        "top_k_probabilities = top_k_probabilities.numpy().tolist()\n",
        "\n",
        "# Display top 3 predictions and their confidence levels\n",
        "for i, (preds, probs) in enumerate(zip(top_k_predictions, top_k_probabilities), 1):\n",
        "    print(f\"Top {i} Predictions:\")\n",
        "    for pred, prob in zip(preds, probs):\n",
        "        print(f\"  Label: {pred}, Confidence Level (%): {prob * 100:.2f}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsI5YaDANzT4",
        "outputId": "0a329f09-d22b-485a-c072-ddb7f79e3b11"
      },
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 Predictions:\n",
            "  Label: Unrelated_Random_Sentence, Confidence Level (%): 32.64\n",
            "  Label: Inventory Inquiry - Product Specific Attributes, Confidence Level (%): 5.54\n",
            "  Label: Request for Sales Breakdown by Hour, Confidence Level (%): 4.73\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample input text\n",
        "input_text = \"forecast for product x for the next 2 semesters\"\n",
        "# Tokenize input text\n",
        "input_encoding = tokenizer(input_text, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Perform prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    input_ids = input_encoding['input_ids']\n",
        "    attention_mask = input_encoding['attention_mask']\n",
        "    logits = model(input_ids, attention_mask=attention_mask).logits\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    top_k_probabilities, top_k_indices = torch.topk(probabilities, k=3, dim=1)\n",
        "\n",
        "# Convert top k predicted labels back to text labels\n",
        "top_k_predictions = [[label_map_inverse[idx.item()] for idx in top_k_indices_row] for top_k_indices_row in top_k_indices]\n",
        "\n",
        "# Convert tensor to list for easier manipulation\n",
        "top_k_probabilities = top_k_probabilities.numpy().tolist()\n",
        "\n",
        "# Display top 3 predictions and their confidence levels\n",
        "for i, (preds, probs) in enumerate(zip(top_k_predictions, top_k_probabilities), 1):\n",
        "    print(f\"Top {i} Predictions:\")\n",
        "    for pred, prob in zip(preds, probs):\n",
        "        print(f\"  Label: {pred}, Confidence Level (%): {prob * 100:.2f}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inJokptNZkcX",
        "outputId": "40a503c4-2755-462d-f8d3-8ba376e23d79"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 Predictions:\n",
            "  Label: Sales Forecast Inquiry - Product Specific - Time Period Specific, Confidence Level (%): 23.22\n",
            "  Label: Request for Sales Breakdown by Product Category, Confidence Level (%): 9.00\n",
            "  Label: Request for Daily Sales Breakdown by Location - Time Horizon Specific, Confidence Level (%): 4.01\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}